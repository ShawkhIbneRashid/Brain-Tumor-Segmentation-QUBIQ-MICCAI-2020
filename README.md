I have worked on the dataset provided by the QUBIQ challenge in MICCAI-2020 for brain tumor segmentation. The dataset is divided into four parts, brain-growth, brain-tumor, prostate and kidney. As I used only the brain-tumor part, I had a small dataset to train my model from. 

There are a total of 40 cases in the train, test, and validation set of the brain-tumor part of this dataset. These images are multidimensional and are of NIfTI format. The ﬁrst image of each case is a 3D brain image, which constitutes four different 2D brain MRI images. The rest of the nine images in each case are segmented ground truth images of the 3D image. Among these nine segmented ground truth images, some can be blank. These ground truths are generated by multiple human experts.

In each case of both the validation set and train set, there were some blank ground truth segmented maps. So, I replaced the blank images with the available segmented images for each case separately. I replaced the blank one with its previous image. If the ﬁrst image was blank, I replaced it with the next ﬁlled image. Again for each case, there was one 3D image containing four 2D image slices. So for four images, there were nine segmented images by experts. So to keep consistency, I copied the ﬁrst image three times, and the rest of the three images two times. So now, each case contained nine 2D images of the brain and nine segmented ground truth images. So before performing these steps, the shape of the train set was (28,4,240,240), but after performing the previously explained procedure, the new shape of the train set became (252, 240, 240). The shape of the training ground truth set was (252, 240, 240). The shape of the validation set was (3, 4, 240, 240), but it was converted to (27, 240, 240). I converted the pixel values in the range from -1 to 1 for the training set. The segmented maps had pixel values of either 0 or 1, where 1 identifying pixel containing the tumors. As the input shape of the proposed model is 256x256x3, I did zero padding to match the height and width of the input shape of the model. Also, I copied one training image two more times in two channels to match the color channel number of the input layer of the proposed model.

At first, I only used the UNet model for training the small train-set. But after training this model for 10 epochs, the model was unable to generate the segmentation masks for the given MRI brain images. So I have utilized the concept of transfer learning for this brain tumor segmentation task, where the train-set is small. I used a pretrained VGG16 on the ImageNet dataset as an encoder, and UNet as a decoder. I used Dice Similarity Coefﬁcient and Jaccard Coefﬁcient as evaluation metrics. This final model after training for 10 epochs was able to segment the brain tumors to some extent.
